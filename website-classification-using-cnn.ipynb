{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn import linear_model\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline \nfrom sklearn.utils import shuffle\nimport matplotlib.pyplot as plt\nfrom numpy import array\nfrom numpy import argmax\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_selection import chi2\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Activation\nfrom keras.utils import np_utils\nimport re\nfrom keras.preprocessing import sequence\nfrom keras.preprocessing.text import one_hot\nfrom keras.preprocessing.text import text_to_word_sequence\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import SGDClassifier","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"names=['URL','Category']\n#df=pd.read_csv( \"../input/website-classification-using-url/URL Classification.csv\")\n#df=pd.read_csv('../input/Website classification using URL/URL Classification.csv')\ndf=pd.read_csv('../input/website-classification-using-url/URL Classification.csv',names=names, na_filter=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlb = LabelEncoder()\nlb.fit(df['Category'])\ndf['Category'] = lb.transform(df['Category'])\n\ndata = pd.get_dummies(df,prefix=['Category'], columns = ['Category'])\ndf = data\ndf[:2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df[1:4000]\ndf2 = df[50000:54000]\ndf3 = df[520000:524000]\ndf4 =df[535300:539300]\ndf5 = df[650000:654000]\ndf6= df[710000:714000]\ndf7=  df[764200:768200]\ndf8=  df[793080:797080]\ndf9=  df[839730:843730]\ndf10=  df[850000:854000]\ndf11=  df[955250:959250]\ndf12=  df[1013000:1017000]\ndf13=  df[1143000:1147000]\ndf14=  df[1293000:1297000]\ndf15=  df[1492000:1496000]\n#df6 = df[77000:1562978]\ndt=pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15], axis=0)\ndf.drop(df.index[1:4000],inplace= True)\ndf.drop(df.index[50000:54000],inplace= True)\ndf.drop(df.index[520000:524000],inplace= True)\ndf.drop(df.index[535300:539300],inplace= True)\ndf.drop(df.index[650000:654000],inplace= True)\ndf.drop(df.index[710000:714000],inplace= True)\ndf.drop(df.index[764200:768200],inplace= True)\ndf.drop(df.index[793080:797080],inplace= True)\ndf.drop(df.index[839730:843730],inplace= True)\ndf.drop(df.index[850000:854000],inplace= True)\ndf.drop(df.index[955250:959250],inplace= True)\ndf.drop(df.index[1013000:1017000],inplace= True)\ndf.drop(df.index[1143000:1147000],inplace= True)\ndf.drop(df.index[1293000:1297000],inplace= True)\ndf.drop(df.index[1492000:1496000],inplace= True)\ndf.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=df['URL']\ny_train=df.iloc[: , 1:16].values\nprint(y_train)\ny_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test=dt['URL']\ny_test=dt.iloc[: , 1:16].values\nprint(y_test)\ny_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"import re\nimport nltk\nfrom sklearn.pipeline import Pipeline\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.snowball import SnowballStemmer\nstemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\nclass StemmedCountVectorizer(CountVectorizer):\n    def build_analyzer(self):\n        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n    \nstemmed_count_vect = StemmedCountVectorizer(stop_words='english', ngram_range=(2,2))\n\ngs_clf = Pipeline([('vect', stemmed_count_vect),\n                   ('tfidf', TfidfTransformer()),\n                   ('clf', SGDClassifier(loss='perceptron', penalty='l2',\n                    alpha =1e-4 , max_iter=20 ,tol=None)),\n   ])\ngs_clf = gs_clf.fit(X_train, y_train)\n"},{"metadata":{},"cell_type":"markdown","source":"**This is for understandind the basics of stemming it transforms the words to its root**\n* >  stem_vectorizer = stemmed_count_vect\n* > text1 = 'Ã¯ am so much bored because of your meaningless behaviour'\n* > print(stem_vectorizer.fit_transform([text1]))\n* > print(stem_vectorizer.get_feature_names())"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\ndef create_and_train_tokenizer(texts):\n    tokenizer=Tokenizer()\n    tokenizer.fit_on_texts(texts)\n    return tokenizer\n\nfrom keras.preprocessing.sequence import pad_sequences\ndef encode_reviews(tokenizer, max_length, docs):\n    encoded=tokenizer.texts_to_sequences(docs) \n    padded=pad_sequences(encoded, maxlen=max_length, padding=\"post\")\n    return padded\n\ntokenizer=create_and_train_tokenizer(texts = X_train)\nvocab_size=len(tokenizer.word_index) + 1\nprint(\"Vocabulary size:\", vocab_size)\n\nmax_length=max([len(row.split()) for row in X_train])\nprint(\"Maximum length:\",max_length)\n\nX_train_encoded = encode_reviews(tokenizer, max_length, X_train)\nX_test_encoded = encode_reviews(tokenizer, max_length, X_test)\nprint('x_train shape:', X_train_encoded.shape)\nprint('x_test shape:', X_test_encoded.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.layers import Embedding\nfrom keras.layers import Conv1D, GlobalMaxPooling1D\nfrom keras.datasets import imdb\nfrom keras import layers, models\nfrom keras.callbacks import EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_encoded[:2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import layers, models\n\ndef create_embedding_model(vocab_size, max_length):\n    model=models.Sequential()\n    model.add(layers.Embedding(vocab_size, 100, input_length=max_length))\n\n    model.add(layers.Conv1D(1024, 5, activation=\"relu\"))\n    #model.add(layers.BatchNormalization())\n    model.add(layers.MaxPooling1D())\n\n    model.add(layers.Conv1D(1024, 5, activation=\"relu\"))\n    #model.add(layers.BatchNormalization())\n    model.add(layers.MaxPooling1D())\n\n    model.add(layers.Flatten())\n    model.add(layers.Dense(512,  activation=\"relu\")) \n    dropout = Dropout(0.5)\n    model.add(layers.Dense(15,  activation=\"softmax\"))   \n    return model\n\nembedding_model = create_embedding_model(vocab_size=vocab_size, max_length=max_length)\nembedding_model.summary()\n\nfrom keras.optimizers import SGD\n#opt = SGD(lr=0.01, momentum=0.9)\nembedding_model.compile(loss='categorical_crossentropy',\n              optimizer= 'adam',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#earlyStopping = EarlyStopping(monitor=\"val_accuracy\", patience=1)\nmodelHistory = embedding_model.fit(X_train_encoded, \n                                   y_train, \n                                   validation_data=(X_test_encoded, y_test),\n                                   epochs= 15\n                                   )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(y_train) + len(y_test))\nprint(len(X_train_encoded))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_, acc = embedding_model.evaluate(X_train_encoded, y_train, verbose=0)\nprint(\"Train accuracy:{:.2f}\".format(acc*100))\n_,acc= embedding_model.evaluate(X_test_encoded, y_test, verbose=0)\nprint(\"Test accuracy:{:.2f}\".format(acc*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"print(gs_clf.predict(['http://www.banglainfotube.com']))\nprint(gs_clf.predict(['http://www.gamespot.net/']))"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n#saving the model\nembedding_model.save('classification_model.h5')\n# Recreate the exact same model, including its weights and the optimizer\nnew_model = tf.keras.models.load_model('classification_model.h5')\n# Show the model architecture\nnew_model.summary()\n# Evaluate the model\nloss, acc = new_model.evaluate(X_test_encoded, y_test, verbose=0)\nprint('Restored model, accuracy 1: {:5.2f}%'.format(100*acc))\n\n''''''''''\n# Save the weights\nmodel.save_weights('./checkpoints/my_checkpoint')\n# Create a new model instance\nmodel = create_model()\n# Restore the weights\nmodel.load_weights('./checkpoints/my_checkpoint')\n# Evaluate the model\nloss,acc = model.evaluate(X_test_encoded, y_test, verbose=0)\nprint(\"Restored model, accuracy 2: {:5.2f}%\".format(100*acc))''''\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_maxlength = 0\nfor text in X_test:\n    length = len(text) \n    if test_maxlength < length:\n        test_maxlength = length\n        ntext = text\n        \nprint('maxlength is {} and text is = {} '.format(test_maxlength , ntext))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}